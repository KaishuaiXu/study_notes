###QA

<img src="/Users/caiyinqiong/Library/Application Support/typora-user-images/image-20191115165547284.png" alt="image-20191115165547284" style="zoom:50%;" />

<img src="/Users/caiyinqiong/Library/Application Support/typora-user-images/image-20191107010348581.png" alt="image-20191107010348581" style="zoom:50%;" />

- **wikiQA**：Yi Yang, Wen-tau Yih, and Christopher Meek. 2015. WikiQA: a challenge dataset for open-domain question answering. In EMNLP.

  > 下载地址：https://www.microsoft.com/en-us/download/details.aspx?id=52419
  >
  > 数据集简介：open-domian factoid QA dataset in which all answers were collected from the Wikipedia.
  >
  > 0/1标签 

- **TRECQA**：Mengqiu Wang, Noah A Smith, and Teruko Mitamura. 2007. What is the Jeopardy model? A quasi-synchronous grammar for QA. In EMNLP-CoNLL

  > 下载地址：https://github.com/aseveryn/deep-qa
  >
  > 数据集简介：QA track (8-13) data of Text REtrieval Conference。factoid question answering。候选答案是单个句子。
  >
  > 0/1标签 

- **InsuranceQA**：Feng, Minwei, Xiang, Bing, Glass, Michael, Wang, Lidan, and Zhou, Bowen. Applying deep learning to answer selection: A study and an open task. IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), 2015.

  > 数据集简介：non-factoid QA dataset from the insurance domain。question may have multiple correct answers and normally the questions are much shorter than the answers. The average length of questions and answers in tokens are 7 and 95, respectively. For each question in the development and test sets, there is a set of 500 candidate answers.

- **Yahoo! Answers**

  > 下载地址：http://answers.yahoo.com
  >
  > 数据集简介：10,000 How questions, each with a communitychosen best answer 

- **FiQA：**

  > 数据集简介：non-factoid QA dataset from the financial domain which has been recently released for WWW 2018 Challenges。。。 The dataset is built by crawling Stackexchange, Reddit and StockTwits in which part of the questions are opinionated, targeting mined opinions and their respective entities, aspects, sentiment polarity and opinion holder.
  >
  > 下载地址：https://sites.google.com/view/fiqa/home
  
- **MSDialog**：

  > 数据集简介：MSDialog dataset is a labeled dialog dataset of question answering (QA) interactions between information seekers and providers from an online forum on Microsoft products. The dataset contains more than 2,000 multi-turn QA dialogs with 10,000 utterances that are annotated with user intent on the utterance level.
  >
  > 下载地址：https://ciir.cs.umass.edu/downloads/msdialog
  
- **WikiHop**：Johannes Welbl, Pontus Stenetorp, and Sebastian Riedel. 2018. Constructing datasets for multi-hop reading comprehension across documents. Transactions of the Association of Computational Linguistics （多选题类型的QA、多段落）

  > 数据集简介：The query of WIKIHOP is constructed with entities and relations from WIKIDATA, while supporting documents are from WIKIREADING. A bipartite graph connecting entities and documents is ﬁrst built and the answer for each query is located by traversal on this graph. Candidates that are type-consistent with the answer and share the same relation in query with the answer are included, resulting in a set of candidates. Thus, WIKIHOP is a multi-choice style reading comprehension data set。。。。。There are totally about 43K samples in training set, 5K samples in development set and 2.5K samples in test set.。。。。The task is to predict the correct answer given a query and multiple supporting documents.。。。。Each question is associated with an average of 13.7 supporting Wikipedia passages, each with 36.4 tokens on average.
  >



### MRC

- **SQuAD**：（单段落、抽取式QA）

  > 1.1版本数据集简介：contains over 100, 000 passage-question pairs。
  >
  > 2.0版本数据集简介：contains about 100, 000 answerable questions and over 50, 000 crowdsourced unanswerable questions towards Wikipedia paragraphs. Moreover, for each unanswerable question, a plausible answer span is annotated.
  >
  > 对抗数据集简介：each passage in **AddSent** contains several sentences that are similar to the question but not contradictory to the answer, while each passage in **AddOneSent** contains a human-approved random sentence that may be unrelated to the passage.

- **NewsQA**：（单段落、抽取式QA）Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bachman, and Kaheer Suleman. 2017. NewsQA: A Machine Comprehension Dataset. 

  > 数据集简介：The NewsQA dataset contains 100k answerable questions from a total of 120k questions.
  >
  > 下载地址：https://datasets.maluuba.com/NewsQA/

- **HotpotQA**：（多段落）Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov, and Christopher D Manning. 2018. HotpotQA: A dataset for diverse, explainable multi-hop question answering.

  > - full-wiki setting：112,779 questions are collected by crowdsourcing based on the ﬁrst paragraphs in Wikipedia documents, 84% of which require multi-hop reasoning. The data are split into a training set (90,564 questions), a development set (7,405 questions) and a test set (7,405 questions). All questions in development and test sets are hard multi-hop cases。。。In the training set, for each question, an answer and paragraphs of 2 gold (useful) entities are provided, with multiple supporting facts, sentences containing key information for reasoning, marked out. There are also 8 unhelpful negative paragraphs for training. During evaluation, only questions are offered and meanwhile supporting facts are required besides the answer.
  >

- **ReCoRD**：（抽取式QA、需要常识推理）Sheng Zhang, Xiaodong Liu, Jingjing Liu, Jianfeng Gao, Kevin Duh, and Benjamin Van Durme. 2018. Record: Bridging the gap between human and machine commonsense reading comprehension.

  > 数据集简介：Reading Comprehension with Commonsense Reasoning Datasetis a large-scale MRC dataset requiring commonsense reasoning. It consists of passage-question-answer tuples, collected from CNN and Daily Mail news articles. In each tuple, the passage is formed by the ﬁrst few paragraphs of a news article, with named entities recognized and marked. The question is a sentence from the rest of the article, with a missing entity speciﬁed as the golden answer. The goal is to ﬁnd the golden answer among the entities marked in the passage, which can be deemed as an extractive MRC task.
  
- **MARCO Q&A + Natural Language Generation**：（生成式QA）

  > 数据集简介：
  >
  > MS-MARCO dataset deﬁnes the task as answering a question from multiple passages and the words in the answer are not necessary in the passages. （即多段落生成式QA任务）There are several related passages for each question in the MS-MARCO dataset. In addition to annotating the answer, MS-MARCO also annotates which passage is correct.
  >
  > The questions are user queries issued to the Bing search engine and the contextual passages are from real web documents. The data has been split into a training set (153,725 QA pairs), a dev set (12,467 QA pairs) and a test set (101,092 questions with unpublished answers).
  >
  > 下载地址：
  
- **NarrativeQA**：（单跳、生成式的QA）



<img src="../images/image-20200111213236074.png" alt="image-20200111213236074" style="zoom:50%;" />

|      | wikiQA      | TRECQA | InsuranceQA |
| ---- | ----------- | ------ | ----------- |
|      | MRR<br>MAP  |        |             |
|      | MRR<br/>MAP |        |             |
|      |             |        |             |
|      |             |        |             |



### Conversational machine comprehension：（对话式的阅读理解）

- **CoQA**：Siva Reddy, Danqi Chen, and Christopher D. Manning. CoQA: A conversational question answering challenge. TACL, 2019. （单跳）

  > 数据集简介：It consists of 127k questions with answers collected from 8k conversations over text passages. It covers seven diverse domains (ﬁve of them are in-domain and two are out-of-domain). The out-of-domain passages only appear in the test set. The average number of question answering turns is more than 15 per passage.  CoQA contains text passages from diverse domains, conversational questions and answers developed for each passage, as well as rationales (i.e., text spans extracted from given passages) to support answers.
  >
  > <img src="../images/image-20191217190530921.png" alt="image-20191217190530921" style="zoom:50%;" />
  >
  > ![image-20191219161354572](../images/image-20191219161354572.png)

- **QuAC**：Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin Choi, Percy Liang, and Luke Zettlemoyer. QuAC : Question answering in context. In EMNLP, 2018.

- **QBLink**：Ahmed Elgohary, Chen Zhao, and Jordan Boyd-Graber. A dataset and baselines for sequential open-domain question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 1077–1083, 2018.

  







### Open-domain QA

<img src="../images/image-20191205191716536.png" alt="image-20191205191716536" style="zoom:50%;" />

- **Quasar-T**：Bhuwan Dhingra, Kathryn Mazaitis, and William W Cohen. QUASAR: Datasets for question answering by search and reading. arXiv preprint arXiv:1707.03904, 2017b.

  > 数据集简介：The data set makes use of the “Lucene index” on the ClueWeb09 corpus. For each question, 100 unique sentence-level passages were collected. These supporting passages are given in an order ranked by a search engine.
  >
  > 下载地址：https://github.com/bdhingra/quasar

- **SearchQA**：Matthew Dunn, Levent Sagun, Mike Higgins, Ugur Guney, Volkan Cirik, and Kyunghyun Cho.

  SearchQA: A new q&a dataset augmented with context from a search engine. arXiv preprint arXiv:1704.05179, 2017.

  > 数据集简介：A dataset of complex questions extracted from Jeopardy! and uses Google to collect about 50 web page snippets as passages for each question.
  >
  > 下载地址：https://github.com/nyu-dl/SearchQA

- **TriviaQA**：Mandar Joshi, Eunsol Choi, Daniel S. Weld, and Luke Zettlemoyer. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, 2017.

  > 数据集简介：collected trivia questions coming from 14 trivia and quiz-league websites, and makes use of the Bing Web search API to collect the top 50 webpages most related to the questions.
  >
  > 下载地址：http://nlp.cs.washington.edu/triviaqa/data/triviaqa-unfiltered.tar.gz

- **SQuAD-open**





### 语义匹配

- **SICK（Sentences Involving Compositional Knowledge）**

  >数据集简介：the similarity degree is denoted by a real number in the range of [1, 5]. SICK comprises 9,927 sentence pairs with 4,500/500/4,927 instances for training/dev/test sets.
  >
  >下载地址：http://clic.cimec.unitn.it/composes/sick.html

- **SciTail**：Tushar Khot, Ashish Sabharwal, and Peter Clark. 2018. SciTail: A textual entailment dataset from science question answering. In AAAI. 

  > 数据集简介：The task involves assessing whether a given premise entails a given hypothesis. The hypotheses in SciTail are created from science questions while the corresponding answer candidates and premises come from relevant web sentences retrieved from a large corpus.

- 



### IR

<img src="/Users/caiyinqiong/Library/Application Support/typora-user-images/image-20191111162751237.png" alt="image-20191111162751237" style="zoom:50%;" />

- **Robust**

- **ClueWeb**

- **AOL search log**：Greg Pass, Abdur Chowdhury, and Cayley Torgeson. A picture of search. In InfoScale, volume 152, pp. 1, 2006.

  > 数据集简介：
  >
  > The queries in this dataset were sampled between 1 March, 2006 and 31 May, 2006. In total there are 16,946,938 queries submitted by 657,426 unique users.
  >
  > 一般对该数据集的处理方法：
  >
  > We removed all non-alphanumeric characters from the queries, applied word segmentation and lowercasing. We deﬁne a session by a 30-minute window of inactive time, and ﬁltered sessions by their lengths (minimum 2, maximum 10). We only kept the most frequent |V | = 100k words and mapped all other words to an <unk> token when constructing the vocabulary. We randomly selected 1,032,459 sessions for training, 129,053 sessions for development and 91,108 sessions for testing, with no overlapping.
  
- **Wikipedia Article Search**：Ledell Yu Wu, Adam Fisch, Sumit Chopra, Keith Adams, Antoine Bordes, and Jason Weston. Starspace: Embed all the things! In Thirty-Second AAAI Conference on Artiﬁcial Intelligence, 2018.

  > 数据集简介：Using the 2016-12-21 dump of English Wikipedia (∼5M articles), the task is given a sentence from an article as a search query, ﬁnd the article it came from. Evaluation ranks the true article (minus the sentence) against 10,000 other articles using retrieval metrics.
  >
  > ![image-20200114114310548](../images/image-20200114114310548.png)





### Dialogue

<img src="/Users/caiyinqiong/Library/Application Support/typora-user-images/image-20191115104207757.png" alt="image-20191115104207757" style="zoom:50%;" />

- **UDC**（Ubuntu Dialog Corpus）：R. Lowe, N. Pow, I. Serban, and J. Pineau. 2015. The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems. CoRR abs/1506.08909 (2015).

  > 数据集简介：multi-turn technical support conversation data collected from the chat logs of the Freenode Internet Relay Chat (IRC) network. It consists of 1 million context-response pairs for training, 0.5 million pairs for validation and 0.5 million pairs for testing. In all the three sets, positive responses are human responses, while negative ones are randomly sampled. The ratio of the positive and the negative is 1:1 in the training set, and 1:9 in both the validation set and the test set.
  >
  > 下载地址：https://www.dropbox.com/s/2fdn26rj6h9bpvl/ubuntu%20data.zip?dl=0 （一个处理后的版本，numbers, urls and paths are replaced by special placeholders）
  
- **Douban**：Yu Wu, Wei Wu, Chen Xing, Ming Zhou, and Zhoujun Li. 2017. Sequential matching network: A new architecture for multi-turn response selection in retrieval-based chatbots. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics.

  > 数据集简介：consists of multiturn Chinese conversations collected from Douban group. There are 1 million context-response pairs for training, 50 thousand pairs for validation, and 6, 670 pairs for testing. In the training set and the validation set, the last turn of each conversation is taken as a positive response and a negative response is randomly sampled. For each context in the test set, 10 response candidates are retrieved from an index and their appropriateness regarding to the context is annotated by human labelers.
  
- JDC：（京东发布的比赛数据集）

  > 数据集简介：consists of 515,686 conversational context-response pairs published by the JD contest.
  >
  > 下载地址：https://www.jddc.jd.com

- **E-commerce Dialogue Corpus**：Zhuosheng Zhang, Jiangtong Li, Pengfei Zhu, Hai Zhao, and Gongshen Liu. 2018b. Modeling multiturn conversation with deep utterance aggregation. In Proceedings of the 27th International Conference on Computational Linguistics,

  > 数据集简介：The data consists of multi-turn realworld conversations between customers and customer service staff in Taobao. It contains 1 million context-response pairs for training, and 10 thousand pairs for validation and test. Positive responses in this data are real human responses, and negative candidates are automatically constructed by ranking the response corpus based on conversation history augmented messages using Apache Lucene. The ratio of the positive and the negative is 1:1 in training and validation, and 1:9 in test.

<img src="../images/image-20200114113705629.png" alt="image-20200114113705629" style="zoom:50%;" />

- **Neurips ConvAI2**：Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston. Personalizing dialogue agents: I have a dog, do you have pets too? In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics.

  > 数据集简介：based on the Persona-Chat dataset. For each response, the model has to pick the correct annotated utterance from a set of 20 choices, where the remaining 19 were other randomly chosen utterances from the evaluation set. Note that in a ﬁnal system however, one would retrieve from the entire training set of over 100k utterances.

- **DSTC7，Track1**：

  > 数据集简介：consists of conversations extracted from Ubuntu chat logs.

- **Ubuntu V2**：Ryan Lowe, Nissan Pow, Iulian Serban, and Joelle Pineau. The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems. In SIGDIAL Conference, 2015.

  > 数据集简介：

- **MSDialog**

  >数据集简介：MSDialog dataset is a labeled dialog dataset of question answering (QA) interactions between information seekers and providers from an online forum on Microsoft products. 
  >
  >该数据集包含一个无标签的总集合  和 有用户意图标签（12种意图）的子集合。
  >
  >无标签总集合的统计信息：
  >
  ><img src="/Users/caiyinqiong/Library/Application Support/typora-user-images/image-20191121163454524.png" alt="image-20191121163454524" style="zoom:50%;" />
  >
  >![image-20191121162806729](/Users/caiyinqiong/Library/Application Support/typora-user-images/image-20191121162806729.png)
  >
  >The dataset contains more than 2,199 multi-turn QA dialogs with 10,020 utterances that are annotated with user intent on the utterance level. 平均每个表达有1.83个标签。
  >
  ><img src="/Users/caiyinqiong/Library/Application Support/typora-user-images/image-20191121162950923.png" alt="image-20191121162950923" style="zoom:25%;" />
  >
  ><img src="/Users/caiyinqiong/Library/Application Support/typora-user-images/image-20191121162708793.png" alt="image-20191121162708793" style="zoom:50%;" />
  >
  >下载地址：https://ciir.cs.umass.edu/downloads/msdialog
  >
  >

- **bAbI dialog** （多轮对话）：Antoine Bordes and Jason Weston. 2016.Learning end-to-end goal-oriented dialog. CoRR.

- **Persona Chat**（多轮对话）：Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston. 2018. Personalizing dialogue agents: I have a dog, do you have pets too?

  > 数据集简介：an open domain dataset with multi-turn chit-chat conversations between turkers who are each assigned a “persona” at random. It comprises of 10.9k dialogs with an average of 14.8 turns per dialog.

- **Dailydialog**（多轮对话）：Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, and Shuzi Niu. 2017. Dailydialog: A manually labelled multi-turn dialogue dataset.

  > 数据集简介：an open domain dataset which consists of dialogs that resemble day-to-day conversations across multiple topics. It comprises of 13k dialogs with an average of 7.9 turns per dialog.

- **MutualFriends**（多轮对话）：H. He, A. Balakrishnan, M. Eric, and P. Liang. 2017. Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings.

  > 数据集简介：a multi-turn goal-oriented dataset where two agents must discover which friend of theirs is mutual based on the friends’ attributes. It contains 11k dialogs with an average of 11.41 utterances per dialog.



###PI

- **MSRP**（Microsoft Research Paraphrase corpus）：Bill Dolan, Chris Quirk, and Chris Brockett. 2004. Unsupervised construction of large paraphrase corpora: exploiting massively parallel news sources. In COLING.

  > 数据集简介：constructed from a large corpus of temporally and topically clustered news articles. 
  >
  > The training set contains 2753 true and 1323 false paraphrase pairs; the test set contains 1147 and 578 pairs，no development set is provided. 
  >
  > 0/1标签

- Wiki Answer（问题复述数据集）：Anthony Fader, Luke S. Zettlemoyer, and Oren Etzioni. 2013. Paraphrase-driven learning for open question answering. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics.

  > 数据集简介：WikiAnswers 是一个英语自然语言问题数据集，从WikiAnswers 网站上抓取的相同问题的不同表述形式，包括 250 万个不同问题和 1800 万个问题复述对。。。每个问题包括多个复述问题。
  >
  > 下载地址：http://dataju.cn/Dataju/publishing/accessContentPublishingDescription/1135

- **PARAGRAM** 预训练词向量

  > 下载地址：http://ttic.uchicago.edu/wieting/
  >
  > 数据集简介：25-dimensional word vectors that are developed for paraphrase tasks





### Knowledge base

- subset of Freebase (FB5M 2 )

  > 下载地址：https://research.facebook.com/researchers/1543934539189348
  >
  > 数据集简介：includes 4,904,397 entities, 7,523 relations, and 22,441,880 facts.

- **ConceptNet**：（Robert Speer, Joshua Chin, and Catherine Havasi. 2016. Conceptnet 5.5: An open multilingual graph of general knowledge. In AAAI Conference on Artiﬁcial Intelligence.）

  > It is a semantic network representing words and phrases as well as the commonsense relationships between them.



### 情感分类

- **MR**：Pang, Bo and Lee, Lillian. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales.

> https://www.cs.cornell.edu/people/pabo/movie-review-data/
>
> 正、负情绪
>
> 电影评论

- **SST（Stanford Sentiment Treebank）**：Socher, Richard, Perelygin, Alex, Wu, Jean Y., Chuang, Jason, Manning, Christopher D., Ng, Andrew Y., and Potts, Christopher. Recursive deep models for semantic compositionality over a sentiment treebank.

> SST-1：an extension of MR but with train/dev/test splits provided and ﬁne-grained labels (very positive, positive, neutral, negative, very negative), re-labeled by Socher et al 。。It has 11855 sentences taken from the movie review site Rotten Tomatoes。。 每个样本是单个句子。。8544 sentences for training, 2210 sentences for test and 1101 sentences for validation。。
>
> 下载地址：http://nlp.stanford.edu/sentiment/ 
>
> SST-2：Same as SST-1 but with neutral reviews removed and binary labels.

- **IMDB**：Maas, Andrew L., Daly, Raymond E., Pham, Peter T., Huang, Dan, Ng, Andrew Y., and Potts, Christopher. Learning word vectors for sentiment analysis.

> 数据集简介：The dataset consists of 100,000 movie reviews（25,000 labeled training instances, 25,000 labeled test instances and 50,000 unlabeled training instances）taken from IMDB。。每个样本包含多个句子。。
>
> 正、负两类标签
>
> 下载地址：http://ai.Stanford.edu/amaas/data/sentiment/index.html



### 摘要

摘要的数据集：https://github.com/mathsyouth/awesome-text-summarization

<img src="../images/image-20191219145644180.png" alt="image-20191219145644180" style="zoom:33%;" />





###其他

**Stanford Parser**: http://nlp.stanford.edu/software/ lex-parser.shtml

**stop word** list: http://snowball. tartarus.org/algorithms/english/stop.txt







