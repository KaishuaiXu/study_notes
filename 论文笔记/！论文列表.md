





# ！WSDM2018（共录取84篇，录取率16%）

- [x] （匹配，迁移学习）Modelling Domain Relationships for Transfer Learning on Chatbot-based Question Answering Systems
- [x] ！！（ConvKNRM）Convolutional Neural Networks for Soft-Matching N-Grams in Ad-hoc Search
- [x] （HyperQA）Hyperbolic Representation Learning for Fast and Efficient Neural Question Answering
- [ ] （XXX）Query Driven Algorithm Selection in Early Stage Retrieval
- [x] ！！（Co-PACRR）ERM-PACRR: A Neural IR model with Enhanced Relevance Matching
- [x] Neural Ranking Models with Multiple Document Fields



# ！WSDM2019

- [ ] （xxxx,ranking）WassRank: Listwise Document Ranking Using Optimal Transport Theory
- [ ] （xxxx,ranking）Joint Optimization of Cascade Ranking Models
- [x] （匹配，迁移学习，强化学习）Learning to Selectively Transfer: Reinforced Transfer Learning for Deep Text Matching
- [x] （QA）Learning to Transform, Combine, and Reason in Open-Domain Question Answering
- [x] （对话）Multi-Representation Fusion Network for Multi-Turn Response Selection in Retrieval-Based Chatbots
- [ ] （XXX,表达学习）SHNE: Representation Learning for Semantic-Associated Heterogeneous Networks.
- [x] （电商）Weakly Supervised Co-Training Query Rewriting and Semantic Matching for E-Commerce
- [x] （推荐）Gated Attentive-Autoencoder for Content-Aware Recommendation
- [x] （推荐）Product-Aware Answer Generation in E-Commerce Question-Answering



# ！SIGIR2018（共录取86篇，录取率21%）

- [x] （IR匹配）Modeling Diverse Relevance Patterns in Ad-hoc Retrieval（范意兴师兄）

- [x] ！！（排序）Learning a Deep Listwise Context Model for Ranking Refinement

- [x] ！！（点击模型）A Click Sequence Model for Web Search

- [x] ！！（多跳问答匹配）Multihop Attention Networks for Question Answer Matching

- [x] ！！（对话系统的response排序）Response Ranking with Deep Matching Networks and External Knowledge in Information-seeking Conversation Systems

- [x] ！！（句子相似度建模、对抗学习）CAN: Enhancing Sentence Similarity Modeling with Collaborative and Adversarial Network

- [x] ！！（CQA的相似问题识别）Related or Duplicate: Distinguishing Similar CQA Questions via Convolutional Neural Networks

- [x] ！！（QA排序、知识库）Knowledge-aware Attentive Neural Network for Ranking Question Answer Pairs

- [x] ！！（融合知识库）Towards Better Text Understanding and Retrieval through Kernel Entity Salience Modeling

- [x] （TREC-CAR任务，对question path进行分段处理）Characterizing Question Facets for Complex Answer Retrieval

- [x] （无监督的QA任务的baseline）Sanity Check: A Strong Alignment and Information Retrieval Baseline for Question Answering

- [x] ！！（IR）Multi-level Abstraction Convolutional Model with Weak Supervision for Information Retrieval

- [ ] ！！（点击相关性数据集）**Sogou-QCL: A New Dataset with Click Relevance Label**

- [ ] ！！（QA数据集）**WikiPassageQA: A Benchmark Collection for Research on Non-factoid Answer Passage Retrieval**

- [x] ！！（对话和用户意图分析的数据集）Analyzing and Characterizing User Intent in Information-seeking Conversations

  

- [ ] ！！（文本生成平台）Texygen: A Benchmarking Platform for Text Generation Models

- [ ] XXX（IR）Modeling multidimensional user relevance in IR using vector spaces

- [ ]  XXX（IR）Are we on the Right Track? Integrating Theoretical and Empirical Methodologies for Information Retrieval

- [ ]  XXX（概率信息检索模型）A New Term Frequency Normalization Model for Probabilistic Information Retrieval

- [ ] XXX（L2R）Universal Approximation Functions for Fast Learning to Rank

- [ ] XXX (搜索的点击模型) Constructing Click Models for Mobile Search

- [ ] XXX（电商搜索中的问题分类）A taxonomy of queries for e-commerce search

- [ ] XXX（问答）Characterizing and Supporting Question Answering in Human-to-Human Communication

- [ ] XXX (搜索结果的多样性) From Greedy Selection to Exploratory Decision-Making: Diverse Ranking with Policy-Value Networks （徐君老师）

- [ ] Predicting User Knowledge Gain in Informational Search Sessions

- [ ] （排序的鲁棒性）Ranking Robustness under Adversarial Document Manipulations

- [ ] ？？（一个信息检索框架）An Information Retrieval Framework for Contextual Suggestion Based on Heterogeneous Information Network Embeddings

- [ ] ？？Deep Semantic Text Hashing with Weak Supervision

- [ ] ？？（排序中的公平性）Equity of Attention: Amortizing Individual Fairness in Rankings

- [ ] ？？Generating Better Queries for Systematic Reviews

- [ ] ？？Neural Compatibility Modeling with Attentive Knowledge Distillation

- [ ] ？？Measuring the Utility of Search Engine Result Pages

- [ ] ？？Ranking Documents by Answer-Passage Quality

- [ ] ？？（相关性的理论）What Can Rationales behind Relevance Judgments Tell Us About Assessor Disagreement?

- [ ] ？？（相关性的理论）Testing the Cluster Hypothesis with Focused and Graded Relevance Judgment

- [ ] ？？Neural Query Performance Prediction using Weak Supervision from Multiple Signals

- [ ] ？？Query Performance Prediction using Passage Information

- [ ] ？？Query Performance Prediction Focused on Summarized Letor Features

- [ ] ？？Query Performance Prediction and Effectiveness Evaluation Without Relevance Judgments: Two Sides of the Same Coin

- [ ] ？？Query Variation Performance Prediction for Systematic Reviews

- [ ] ？？Efficient Exploration of Gradient Space for Online Learning to Rank

- [ ] ？？Selective Gradient Boosting for Effective Learning to Rank

- [ ] ？？Item Retrieval as Utility Estimation

- [ ] ？？Attention-based Hierarchical Neural Query Suggestion

- [ ] ？？Optimizing Query Evaluations using Reinforcement Learning for Web Search

- [ ] （network embedding）BiNE: Bipartite Network Embedding

- [ ] Translating Representations of Knowledge Graphs with Neighbors





# ？SIGIR2019



# WWW2018

# WWW2019





# ACL2018



# ！ACL2019

- [x] RankQA: Neural Question Answering with Answer Re-Ranking 
- [x] Episodic Memory Reader: Learning What to Remember for Question Answering from Streaming Data 
- [x] Retrieve, Read, Rerank: Towards End-to-End Multi-Document Reading Comprehension
- [x] Latent Retrieval for Weakly Supervised Open Domain Question Answering
- [x] Multi-Hop Paragraph Retrieval for Open-Domain Question Answering
- [x] Real-Time Open-Domain Question Answering with Dense-Sparse Phrase Index
- [x] A cross-sentence latent variable model for semi-supervised sequence matching
- [x] Answering while Summarizing: Multi-task Learning for Multi-hop QA with Evidence Extraction 
- [x] Learning a Matching Model with Co-teaching for Multi-turn Response Selection in Retrieval-based Dialogue Systems
- [x] Matching Article Pairs with Graphical Decomposition and Convolutions
- [x] RE2: Simple and Effective Text Matching with Richer Alignment Features

- [x] A Lightweight Recurrent Network for Sequence Modeling
- [x] Encouraging Paragraph Embeddings to Remember Sentence Identity Improves Classification
- [x] Pretraining Methods for Dialog Context Representation Learning
- [x] Relational Word Embeddings
- [x] Training Neural Response Selection for Task-Oriented Dialogue Systems
- [x] Learning Transferable Feature Representations Using Neural Networks




第一次阅读列表

- [ ] ~~（没看论坛上的帖子）Entity-Relation Extraction as Multi-Turn Question Answering~~

- [x] ！！（多段落MRC）**Multi-hop reading comprehension across multiple documents by reasoning over heterogeneous graphs**

- [x] ！！（生成式MRC）**Multi-style Generative Reading Comprehension** 【基于transformer】

- [ ] ~~（多标签分类、强化学习）A Deep Reinforced Sequence-to-Set Model for Multi-Label Classification~~

- [ ] ~~Is Attention Interpretable?~~ 【论坛上的帖子写的很清晰】

- [x] **（NLI数据集中的bias问题）Don’t Take the Premise for Granted: Mitigating Artifacts in Natural Language Inference 【给定假设和label，预测前提。。。方法新颖，但没看懂帖子】**

- [ ] ~~（跨语言检索）Improving Low-Resource Cross-lingual Document Retrieval by Reranking with Deep Bilingual Representations~~ 【论坛上的帖子写的很清晰】

- [ ] （MRC、推理）Inferential Machine Comprehension: Answering Questions by Recursively Deducing the Evidence Chain from Text 【模型很复杂，，主要针对多步推理】

- [ ] （~~跨语言的开放域QA数据集）XQA: A Cross-lingual Open-domain Question Answering Dataset  【不咋关心范围内】~~

- [ ] ~~（社交媒体QA数据集）TWEETQA: A Social Media Focused Question Answering Dataset~~

- [ ] ~~！！（抽取式摘要）HIBERT: Document Level Pre-training of Hierarchical Bidirectional Transformers for Document Summarization~~ 【一个基于transformer的针对抽取式摘要任务的预训练模型，，论坛上的帖子写的很清晰】

  

第二次论文列表（20篇）

- [x] ！！（MRC，外部知识）**Explicit Utilization of General Knowledge in Machine Reading Comprehension**【提出一种使用外部知识WordNet的方式】
- [x] ！！（MRC）**Token-level Dynamic Self-Attention Network for Multi-Passage Reading Comprehension**【提出词级别的动态self-attention机制用于多段落MRC】
- [ ] ~~（表示学习）Relating Simple Sentence Representations in Deep Neural Networks and the Brain【分析类论文，涉及生理学，比较学习到的句子表示与人脑中形成的表示之间的关系】~~
- [ ] ~~（模型评价，不在关注范围内）Deep Dominance - How to Properly Compare Deep Neural Models~~
- [x] ！！（多任务学习）**Multi-Task Deep Neural Networks for Natural Language Understanding** 【在BERT的基础上对GLUE的所有任务联合学习】
- [ ] ~~（跨语言迁移学习，不在关注范围内）Multi-Source Cross-Lingual Model Transfer: Learning What to Share~~
- [ ] ~~（表示学习）Is Word Segmentation Necessary for Deep Learning of Chinese Representations? 【分析类，分析中文分词对中文类任务的必要性】~~
- [ ] ~~Selection Bias Explorations and Debias Methods for Natural Language Sentence Matching Datasets【主要解决文本匹配数据集中存在的bias问题】~~
- [x] （无监督MRC数据集生成）Unsupervised Question Answering by Cloze Translation
- [x] ！！（BERT+知识图谱）ERNIE: Enhanced Language Representation with Informative Entities
- [ ] ~~（QA）Interpretable Question Answering on Knowledge Bases and Text  【主要注重可解释的QA】~~
- [ ] ~~（新数据集）ELI5: Long Form Question Answering~~
- [x] ！！（问题生成）**Learning to Ask Unanswerable Questions for Machine Reading Comprehension** 【论坛上的帖子没太看懂具体方法，但感觉有价值】
- [x] ！！（QA对生成）**Generating Question-Answer Hierarchies** 【论坛上的帖子没太看懂具体方法，但感觉有价值】
- [x] ！！（MRC）**Exploiting Explicit Paths for Multi-hop Reading Comprehension**
- [x] ！！（self-attention）**Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned**
- [x] ！！（对话）**One Time of Interaction May Not Be Enough: Go Deep with an Interaction-over-Interaction Network for Response Selection in Dialogues**  【论坛上的帖子没太看懂具体方法，但感觉有价值】



第三次论文列表

- [x] ！！（QA模型的鲁棒性）**Improving the Robustness of Question Answering Systems to Question Paraphrasing**
- [ ] ~~StRE: Self Attentive Edit Quality Prediction in Wikipedia~~
- [x] **！！（对话的问题生成）Reinforced Dynamic Reasoning for Conversational Question Generation**
- [x] **Transformer-XL: Attentive Language Models beyond a Fixed-Length Context   **【循环机制 + 相对位置编码】
- [ ] ~~Jointly Learning Semantic Parser and Natural Language Generator via Dual Information Maximization~~  【数学性较强】
- [x] ！！！（多跳MRC）**Cognitive Graph for Multi-Hop Reading Comprehension at Scale** 【用两个system解决多跳MRC的推理】
- [ ] （~~语义解析，不在研究范围内）AdaNSP: Uncertainty-driven Adaptive Decoding in Neural Semantic Parsing~~
- [ ] Explain Yourself! Leveraging Language Models for Commonsense Reasoning
- [ ] ~~Better Character Language Modeling through Morphology~~
- [x] ！！！（开放域QA）**Improving Question Answering over Incomplete KBs with Knowledge-Aware Reader**【为了弥补KB无法提供开放域QA所需的全部知识，因此考虑加入一些非结构化文本知识】
- [x] ！！（多跳MRC）Multi-hop Reading Comprehension through Question Decomposition and Rescoring
- [x] ！！（MRC）Enhancing Pre-Trained Language Representations with Rich Knowledge for Machine Reading Comprehension 【在BERT上加入知识库】
- [x] **（对话式QA）MCˆ2: Multi-perspective Convolutional Cube for Conversational Machine Reading Comprehension**
- [x] MultiQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension
- [x] ！！（对话）**Are Training Samples Correlated? Learning to Generate Dialogue Responses with Multiple References**【建模并利用多个valid response之间的关系】
- [x] ！！（对话）**Conversing by Reading: Contentful Neural Conversation with On-demand Machine Reading**【融合外部知识，帮助对话系统生成response。。同时提供了一个包括外部知识的新数据集】
- [ ] ~~Zero-Shot Entity Linking by Reading Entity Descriptions~~





- [x] ！！（对话）Improving Multi-turn Dialogue Modelling with Utterance ReWriter

- [x] （对话）Do Neural Dialog Systems Use the Conversation History Effectively? An Empirical Study

- [x] ！！（对话系统）Reading Turn by Turn: Hierarchical Attention Architecture for Spoken Dialogue Comprehension

- [x] （对话，response生成）Incremental Transformer with Deliberation Decoder for Document Grounded Conversations

- [x] （对话，response选择）Constructing Interpretive Spatio-Temporal Features for Multi-Turn Responses Selection

- [x] （对话生成）ReCoSa: Detecting the Relevant Contexts with Self-Attention for Multi-turn Dialogue Generation

- [x] （response 生成）Retrieval-Enhanced Adversarial Training for Neural Response Generation

- [x] （response 生成）Learning to Abstract for Memory-augmented Conversational Response Generation

- [x] （response 生成）Neural Response Generation with Meta-words

- [ ] ~~（response 生成）Boosting Dialog Response Generation 【设计一种基于boost的迭代训练过程和集成方法来提高生成的response的多样性】~~

- [ ] ~~（元学习、对话系统）Personalizing Dialogue Agents via Meta-Learning 【将元学习应用到个性化对话生成中，将学习不同的个性化角色Persona视为不同的任务，评估数据集是Persona Chat】~~

- [x] （对话，元学习）Domain Adaptive Dialog Generation via Meta Learning

- [ ] ~~XXXX（自然语言生成）Constrained Decoding for Neural NLG from Compositional Representations in Task-Oriented Dialogue~~

- [x] ！！（不可回答的问题生成）Self-Attention Architectures for Answer-Agnostic Neural Question Generation

- [x] （图网络、多跳推理）Dynamically Fused Graph Network for Multi-hop Reasoning

  

- [ ] （QA）~~NLProlog: Reasoning with Weak Unification for Question Answering in Natural Language~~【multihop qa，想把自然语言文本转换成logic form，通过一个个logic form推导出最后的答案。】

- [x] ！！（多步推理）Compositional Questions Do Not Necessitate Multi-hop Reasoning

- [x] （MRC）Simple and Effective Curriculum Pointer-Generator Networks for Reading Comprehension over Long Narratives 

- [ ] （MRC）~~E3: Entailment-driven Extracting and Editing for Conversational Machine Reading~~ 【文章针对一个对话机器阅读理解任务的新形式（CMR， ShARC）：这个任务要求模型会根据规则文本以及场景描述文本来回答用户的一个初始问题。这个初始问题是无法直接根据rule和scenario回答的，因为缺少一些信息，所以需要模型询问follow up question，最后回答的问题，选项只有yes/no/irrelevant，具体可能要看ShARC数据集介绍。】

- [x] （MRC）Explore, Propose, and Assemble: An Interpretable Model for Multi-Hop Reading Comprehension

- [x] ！！（预训练，迁移学习，自然语言生成）Large-Scale Transfer Learning for Natural Language Generation

  

- [x] Learning Compressed Sentence Representations for On-Device Text Processing

- [ ] （一个新的NLI数据集）~~SherLIiC: A Typed Event-Focused Lexical Inference Benchmark for Evaluating Natural Language Inference~~

- [x] （BERT可解释性）What Does BERT Learn about the Structure of Language

- [x] Dual Supervised Learning for Natural Language Understanding and Generation

  

- [x] （梯度反转，域适应）Reversing Gradients in Adversarial Domain Adaptation for Question Deduplication and Textual Entailment Tasks

- [x] （知识蒸馏，多任务学习）BAM! Born-Again Multi-Task Networks for Natural Language Understanding

  

  

 



# EMNLP2018

- [ ] Minjoon Seo, Tom Kwiatkowski, Ankur Parikh, Ali Farhadi, and Hannaneh Hajishirzi. 2018. Phraseindexed question answering: A new challenge for scalable document comprehension.





# ？EMNLP2019

- [x] （外部知识，生成式QA）Incorporating External Knowledge into Machine Reading for Generative Question Answering
- [x] Multi-hop Selector Network for Multi-turn Response Selection in Retrieval-based Chatbots
- [x] Enhancing Local Feature Extraction with Global Representation for Neural Text Classification
- [x] Evaluation Benchmarks and Learning Criteria for Discourse-Aware Sentence Representations
- [x] ~~（句子表示学习）Parameter-free Sentence Embedding via Orthogonal Basis~~
- [x] Hierarchical Modeling of Global Context for Document-Level Neural Machine Translation
- [x] Multi-Granularity Representations of Dialog
- [x] ！！**PullNet: Open Domain Question Answering with Iterative Retrieval on Knowledge Bases and Text**
- [x] ~~Finding Generalizable Evidence by Learning to Convince Q&A Models~~ （对于多选题类型的QA，每个agent为每个候选答案找对应的evidence sentence，然后有一个judge model来判断最终的答案）
- [x] ！！**Ranking and Sampling in Open-Domain Question Answering**
- [x] ~~Answering questions by learning to rank - Learning to rank by answering questions~~（对于多选题类型的QA，对IR系统检索得到的topN文档进行语义排序）
- [x] ！！Revealing the Importance of Semantic Retrieval for Machine Reading at Scale
- [ ] Quick and (not so) Dirty: Unsupervised Selection of Justification Sentences for Multi-hop Question Answering
- [ ] Answering Complex Open-domain Questions Through Iterative Query Generation
- [ ] Original Semantics-Oriented Attention and Deep Fusion Network for Sentence Matching
- [ ] Asynchronous Deep Interaction Network for Natural Language Inference
- [ ] Interactive Language Learning by Question Answering
- [ ] What’s Missing: A Knowledge Gap Guided Approach for Multi-hop Question Answering
- [ ] Extractive Summarization of Long Documents by Combining Global and Local Context
- [ ] Concept Pointer Network for Abstractive Summarization
- [ ] 







- [ ]  （文本生成）Attending to Future Tokens for Bidirectional Sequence Generation
- [ ]  （在预训练中融入实体信息）Knowledge Enhanced Contextual Word Representations
- [ ]  （对上下文词向量的分析）How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings
- [ ]  Entity-Consistent End-to-end Task-Oriented Dialogue System with KB Retriever
- [ ]  Tree Transformer: Integrating Tree Structures into Self-Attention
- [ ]  Incorporating Contextual and Syntactic Structures Improves Semantic Similarity Modeling
- [ ]  Attention Optimization for Abstractive Document Summarization
- [ ]  Neural Duplicate Question Detection without Labeled Training Data
- [ ]  Multi-View Domain Adapted Sentence Embeddings for Low-Resource Unsupervised Duplicate Question Detection
- [ ]  Hierarchy Response Learning for Neural Conversation Generation
- [ ]  Knowledge Aware Conversation Generation with Explainable Reasoning over Augmented Graphs
- [ ]  Adaptive Parameterization for Neural Dialogue Generation
- [ ]  Retrieval-guided Dialogue Response Generation via a Matching-to-Generation Framework
- [ ]  Generating Questions for Knowledge Bases via Incorporating Diversified Contexts and Answer-Aware Loss
- [ ]  Incorporating External Knowledge into Machine Reading for Generative Question Answering
- [ ]  

----------

Mixture Content Selection for Diverse Sequence Generation





# NAACL2018

# NAACL2019





# AAAI2018

# AAAI2019

# IJCAI2018

# IJCAI2019



# ！ICLR2018

（2.3%的口头展示，31.4%的poster接受，9%的workshop）

- [x] ！！！！（DIIN）Natural Language Inference over Interaction Space

- [x] ！！！！（IR，多任务学习）Multi-Task Learning for Document Ranking and Query Suggestion 

- [x] ！！！！（表达学习）An efficient framework for learning sentence representations

- [x] ！！（表达学习，多任务学习）Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning

- [x] ！！！！（序列建模）Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence Modeling

- [x] ！！！！（开放域QA）Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering

- [x] ！！！（QA，强化学习）Ask the Right Questions: Active Question Reformulation with Reinforcement Learning

- [x] ！！（MRC）QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension

- [x] ！！（MRC）DCN+: Mixed Objective And Deep Residual Coattention for Question Answering

- [x] ！！（MRC）FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension

  

- [x] （MRC）Multi-Mention Learning for Reading Comprehension with Neural Cascades 

- [x] （摘要）Generating Wikipedia by Summarizing Long Sequences 

- [x] （表达学习）A New Method of Region Embedding for Text Classification 

  

- [ ] （语言模型）breaking_the_softmax_bottleneck：a_high_rank_rnn_language_model

- [ ] （语言模型）Neural Language Modeling by Jointly Learning Syntax and Lexicon

- [ ] （文本生成，GAN）MaskGAN: Better Text Generation via Filling in the _______ 

- [ ] （摘要）A Deep Reinforced Model for Abstractive Summarization

- [ ] （LSTM的可解释性，情感分析）Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs

- [ ] （迁移学习）Minimal-Entropy Correlation Alignment for Unsupervised Deep Domain Adaptation

- [ ] （图卷积+self-attention）Graph Attention Networks

- [ ] （多任务学习）Routing Networks: Adaptive Selection of Non-Linear Functions for Multi-Task Learning 

- [ ] All-but-the-Top: Simple and Effective Postprocessing for Word Representations

- [ ] ！！（一个逻辑蕴含的数据集）Can Neural Networks Understand Logical Entailment? 

- [ ] Spherical CNNs

- [ ] （多任务学习）Beyond Shared Hierarchies: Deep Multitask Learning through Soft Layer Ordering

- [ ] （transformer-based）Non-Autoregressive Neural Machine Translation



# ICLR2019

- [x] （面向任务型对话系统）Global-to-local Memory Pointer Networks for Task-Oriented Dialogue
- [x] 方法过于数学（对话系统的问题生成）Large-Scale Answerer in Questioner's Mind for Visual Dialog Question Generation
- [x] （对话系统）Wizard of Wikipedia: Knowledge-Powered Conversational Agents
- [x] （NLU）GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding 
- [x] （多文档QA）Coarse-grain Fine-grain Coattention Network for Multi-evidence Question Answering
- [x] （开放域QA）Multi-step Retriever-Reader Interaction for Scalable Open-domain Question Answering
- [x] 论文写得很不清晰（QA）Generative Question Answering: Learning to Answer the Whole Question
- [x] （对话式QA）flowQA




- [ ] （对话系统）Detecting Egregious Responses in Neural Sequence-to-sequence Models 
- [ ] （信息检索）textTOvec: DEEP CONTEXTUALIZED NEURAL AUTOREGRESSIVE TOPIC MODELS OF LANGUAGE WITH DISTRIBUTED COMPOSITIONAL PRIOR

- [ ] Posterior Attention Models for Sequence to Sequence Learning

- [ ] Universal Transformers 
- [ ] Trellis Networks for Sequence Modeling
- [ ] 



# ！ICLR2020

第一次阅读列表：

- [x] ！！！**NeurQuRI: Neural Question Requirement Inspector for Answerability Prediction in Machine Reading Comprehension**【提出一个比较好用的 answerability 判定模块，可借鉴到qq匹配任务上】
- [x] ！！！（对话、外部知识）**Sequential Latent Knowledge Selection for Knowledge-Grounded Dialogue**【对话任务，如何更好地选择知识】
- [x] **TinyBERT: Distilling BERT for Natural Language Understanding**
- [x] **StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding**
- [x] **ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators**【对bert预训练任务的改进】
- [x] Neural Symbolic Reader: Scalable Integration of Distributed and Symbolic Representations for Reading Comprehension
- [x] （和我的研究好像很像）Poly-encoders: Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring
- [x] （对BERT的改进）ALBERT: A Lite BERT for Self-supervised Learning of Language Representations
- [x] （对BERT的改进）RoBERTa: A Robustly Optimized BERT Pretraining Approach
- [x] （对话生成，低资源）Low-Resource Knowledge-Grounded Dialogue Generation 【论坛上写的很清晰，方法简明，不用再看了】
- [ ] **A Theoretical Analysis of the Number of Shots in Few-Shot Learning**
- [ ] **Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity**【提供了梯度剪裁在训练深度神经网络时有效性的合理解释】
- [ ] **On Identifiability in Transformers** 【？？？？】
- [ ] ~~Revisiting Self-Training for Neural Sequence Generation【在翻译和摘要任务上进行，论坛上的帖子看不懂，不知道什么叫self-training】~~
- [ ] ~~Controlling generative models with continuous factors of variations~~
- [ ] ~~Understanding and Improving Information Transfer in Multi-Task Learning【对多任务学习提出了理论分析】~~
- [ ] （~~编码词的位置信息）Encoding word order in complex embeddings 【在复数域建模position embedding 表达】~~
- [ ] ~~Improving Adversarial Robustness Requires Revisiting Misclassified Examples~~
- [ ] ~~（CNN、图像、位置信息编码）How much Position Information Do Convolutional Neural Networks Encode? 【实验表明，位置信息是隐式地从padding 操作中学习的】~~
- [ ] ~~Ensemble Distribution Distillation~~
- [ ] ~~SELF: Learning to Filter Noisy Labels with Self-Ensembling~~
- [ ] ~~Cross-Domain Few-Shot Classification via Learned Feature-Wise Transformation~~



第二次阅读列表：

- [x] **！！！！（多跳QA）Transformer-XH: Multi-hop question answering with eXtra Hop attention**
- [x] **！！！！（问题生成）Reinforcement Learning Based Graph-to-Sequence Model for Natural Question Generation**
- [x] （QA、推理）**Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering**
- [x] ！！！（BERT、机器翻译）**Incorporating BERT into Neural Machine Translation**【不直接使用BERT初始化模型，本文是把BERT的输出融入到SEQ2SEQ模型的每一层，用在每个self-attention之中。此外，本文还提出drop-net——随机丢弃BERT表示或模型本身的表示，充分利用两个方面的信息。实验结果还不错。】
- [x] ！！！（互信息最大化、表达学习）**A Mutual Information Maximization Perspective of Language Representation Learning**
- [ ] ~~Simple and Effective Regularization Methods for Training on Noisily Labeled Data with Generalization Guarantee~~
- [ ] ~~Rethinking the Security of Skip Connections in ResNet-like Neural Networks~~
- [ ] ~~Simplified Action Decoder for Deep Multi-Agent Reinforcement Learning~~
- [ ] **A Generalized Training Approach for Multiagent Learning**【？？？？？】
- [ ] ~~Large Batch Optimization for Deep Learning: Training BERT in 76 minutes~~
- [ ] ~~Principled Weight Initialization for Hypernetworks~~
- [ ] ~~BackPACK: Packing more into Backprop~~
- [ ] **You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings**
- [ ] ~~Mirror-Generative Neural Machine Translation~~【利用非平行语料增强翻译效果】
- [ ] ~~Can gradient clipping mitigate label noise?~~
- [ ] **Learning Robust Representations via Multi-View Information Bottleneck**
- [ ] ~~On the Weaknesses of Reinforcement Learning for Neural Machine Translation~~
- [ ] ~~Data-dependent Gaussian Prior Objective for Language Generation~~
- [ ] ~~Query2box: Reasoning over Knowledge Graphs in Vector Space Using Box Embeddings~~【知识图谱上的推理】



- [ ] （对抗学习~~）**FreeLB: Enhanced Adversarial Training for Language Understanding** 【看不太懂】~~
- [ ] （~~互信息最大化、表达学习）**On Mutual Information Maximization for Representation Learning**~~
- [ ] （多任务学习）**Sharing Knowledge in Multi-Task Deep Reinforcement Learning**  【好像数学性过高】
- [ ] （迁移学习，多任务学习）**Understanding and Improving Information Transfer in Multi-Task Learning** 【好像数学性过高】
- [x] **（基于知识的预训练语言模型）Pretrained Encyclopedia: Weakly Supervised Knowledge-Pretrained Language Model** 【论坛上写的很清楚】
- [ ] （新的阅读理解数据集）ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning
- [ ] ！！（对transformer的理解）Are Transformers universal approximators of sequence-to-sequence functions?
- [ ] ！！（Transformer的可解释性）Robustness Verification for Transformers 
- [ ] ！！（Transformer）On the Relationship between Self-Attention and Convolutional Layers【好像不少数学 推理】
- [x] **（预训练的检索模型）GOING BEYOND TOKEN-LEVEL PRE-TRAINING FOR EMBEDDING-BASED LARGE-SCALE RETRIEVAL** 【论坛上写的很清楚】
- [ ] （学习word embedding）DeFINE: Deep Factorized Input Word Embeddings for Neural Sequence Modeling
- [ ] （MRC、推理）**Neural Module Networks for Reasoning over Text** 

- [ ] ！！Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models

- [ ] （文本生成、对抗学习）Self-Adversarial Learning with Comparative Discrimination for Text Generation

  





# CIKM2018

- [ ] From Neural Re-Ranking to Neural Ranking: Learning a Sparse Representation for Inverted Indexing



# ？CIKM2019





















